
@incollection{krcmar_big_2014,
	location = {Wiesbaden},
	title = {Big Data Eine interdisziplinäre Chance für die Wirtschaftsinformatik},
	pages = {281--287},
	booktitle = {Wirtschaftsinformatik : {WI} ; Organ der Fachbereichs Wirtschaftsinformatik der Gesellschaft für Informatik e.V. und der Wissenschaftlichen Kommission Wirtschaftsinformatik im Verband der Hochschullehrer für Betriebswirtschaft e.V.},
	publisher = {Springer Gabler},
	author = {Krcmar, Helmut and Schermann, Michael and Hemsen, Holmer and Markl, Volker and Buchmüller, Christoph and Bitter, Till and Hoeren, Thomas},
	date = {2014},
	keywords = {external},
}

@book{konig_big_2018,
	location = {Wiesbaden},
	title = {Big Data: Chancen, Risiken, Entwicklungstendenzen},
	publisher = {Springer {VS}},
	author = {König, Christian and Schröder, Jette and Wiegand, Erich},
	date = {2018},
	keywords = {external},
}

@book{fasel_big_2016,
	location = {Wiesbaden},
	title = {Big Data: Grundlagen, Systeme und Nutzungspotenziale},
	publisher = {Springer Vieweg},
	author = {Fasel, Daniel and Meier, Andreas},
	date = {2016},
	keywords = {external},
}

@book{santos_big_2020,
	location = {Portugal},
	title = {Big Data : Concepts, Warehousing, and Analytics},
	publisher = {River Publishers},
	author = {Santos, Maribel Yasmina and Costa, Carlos},
	date = {2020},
	keywords = {external},
}

@online{woodie_big_2018,
	title = {Big Data File Formats Demystified},
	url = {https://www.datanami.com/2018/05/16/big-data-file-formats-demystified/},
	abstract = {So you're filling your Hadoop cluster with reams of raw data, and your data analysts and scientists are champing at the bit to get started. Then the},
	titleaddon = {Datanami},
	author = {Woodie, Alex},
	urldate = {2022-12-23},
	date = {2018-05-16},
	file = {Snapshot:/Users/I538983/Zotero/storage/ZAH6BEN4/big-data-file-formats-demystified.html:text/html},
}

@online{apache_apache_nodate,
	title = {Apache Parquet Documentation},
	url = {https://parquet.apache.org/docs/},
	abstract = {The Apache Parquet Website},
	titleaddon = {Apache Parquet},
	author = {Apache},
	urldate = {2022-12-23},
	langid = {english},
	file = {Snapshot:/Users/I538983/Zotero/storage/DBJKSUGP/docs.html:text/html},
}

@online{apache_languagemanual_nodate,
	title = {{LanguageManual} {ORC}},
	url = {https://cwiki.apache.org/confluence/display/hive/languagemanual+orc},
	author = {Apache},
	urldate = {2022-12-23},
	file = {LanguageManual ORC - Apache Hive - Apache Software Foundation:/Users/I538983/Zotero/storage/K7KG5Y4Y/languagemanual+orc.html:text/html},
}

@online{apache_avro_nodate,
	title = {Avro Specification},
	url = {https://avro.apache.org/docs/1.11.1/specification/},
	titleaddon = {Apache Avro},
	author = {Apache},
	urldate = {2022-12-23},
	langid = {english},
	file = {Snapshot:/Users/I538983/Zotero/storage/AE7SW6HW/_print.html:text/html},
}

@online{cloudera_orc_nodate,
	title = {{ORC} vs Parquet formats {\textbar} {CDP} Public Cloud},
	url = {https://docs.cloudera.com/runtime/7.2.10/using-hiveql/topics/hive-orc-parquet-compare.html?},
	author = {Cloudera},
	urldate = {2022-12-23},
	file = {ORC vs Parquet formats | CDP Public Cloud:/Users/I538983/Zotero/storage/JH2VQS93/hive-orc-parquet-compare.html:text/html},
}

@online{kurami_big_nodate,
	title = {Big Data File Formats},
	url = {https://www.hcltech.com/blogs/big-data-file-formats},
	abstract = {Choosing the correct file format is one of the crucial steps in big-data projects. Whenever we deal with {MapReduce} and Spark, the prime concern is the time that it takes to find the relevant/proper information/data from its location. This may impact the performance of the complete job. A proper file format plays a vital role in Big Data projects.},
	titleaddon = {{HCLTech}},
	author = {Kurami, Rashimi},
	urldate = {2022-12-25},
	langid = {english},
	file = {Snapshot:/Users/I538983/Zotero/storage/7FNHLRUI/big-data-file-formats.html:text/html},
}

@incollection{gohil_compendious_2022,
	location = {Madurai, Indien},
	title = {A Compendious Research on Big Data File Formats},
	abstract = {In modern times, the net amount of data
generated is significantly higher than in previous times, and
such data is enormous, complex and hard to manage. The field
which deals with such kind of data is known as Big Data. Big
Data has helped people understand and get a much better grasp
of such complex data. It has also helped extract and analyse
information from such data. Big Data is a prominent and
promising field, and the three essential factors of big data are
volume, variety, and velocity. Big data can be stored in different
file formats. File formats play a vital role in big data, influencing
the two most essential factors, volume and velocity. The file
formats have to be chosen very carefully as they have a domino
effect over the speed or velocity of the particular tasks that have
to be carried out on the big data. So, a comprehensive study of
the following formats {CSV} (Comma-Separated Values), {JSON}
({JavaScript} Object Notation), Avro, Parquet, {ORC} (Optimized
Row Columnar) and {XML} (Extensible Markup Language), has
been carried out. The quantitative analysis has been carried
both on premise and on the cloud},
	booktitle = {2022 6th International Conference on Intelligent Computing and Control Systems ({ICICCS})},
	publisher = {{IEEE}},
	author = {Gohil, Arnav and Shroff, Anshul and Kumar, Shailender and Garg, Arnav},
	date = {2022},
}

@incollection{munir_cost-based_2020,
	title = {A cost-based storage format selector for materialized results in big data frameworks},
	volume = {38},
	booktitle = {Distributed and Parallel Databases},
	publisher = {Springer Science+Business Media},
	author = {Munir, Rana Faisal and Abelló, Alberto and Romero, Oscar and Thiele, Maik and Lehner, Wolfgang},
	date = {2020},
}

@book{plase_comparison_2017,
	location = {Riga, Lettland},
	title = {A Comparison of Hdfs Compact Data formats: Avro versus Parquet},
	publisher = {University of Latvia, Riga Technical University},
	author = {Plase, Daiga and Niedrite, Laila and Taranovs, Romans},
	date = {2017},
}

@book{belov_experimental_2021,
	location = {Moskau, Russland},
	title = {Experimental Characteristics Study of Data Storage Formats for Data Marts Development within Data Lakes},
	publisher = {Russian Technological University, Sechenov First Moscow Stats Medical University},
	author = {Belov, Vladimir and Kosenkov, Alexander N. and Nikulchev, Evgeny},
	date = {2021},
}

@online{luminousmencom_big_nodate,
	title = {Big Data File formats},
	url = {https://luminousmen.com/post/big-data-file-formats},
	abstract = {Which one data format do you pick for your next Big Data project: {CSV}, {JSON}, Parquet and Avro?},
	titleaddon = {Blog {\textbar} iamluminousmen},
	author = {Luminousmen.com},
	urldate = {2022-12-25},
	langid = {english},
	file = {Snapshot:/Users/I538983/Zotero/storage/G5DZPF6D/big-data-file-formats.html:text/html},
}

@online{yadav_all_2022,
	title = {All About Big Data File Formats},
	url = {https://www.analyticsvidhya.com/blog/2022/05/all-about-big-data-file-formats/},
	abstract = {In this article we will be studying A to Z about Big Data File Formats. Its pros \& cons and why people should pivot with this.},
	titleaddon = {Analytics Vidhya},
	author = {Yadav, Kishan},
	urldate = {2022-12-25},
	date = {2022},
	langid = {english},
	file = {Snapshot:/Users/I538983/Zotero/storage/Q5WBMKPS/all-about-big-data-file-formats.html:text/html},
}

@incollection{delplanque_relational_2018,
	location = {Lille, Frankreich},
	title = {Relational Database Schema Evolution: An Industrial Case Study},
	booktitle = {{IEEE} International Conference on Software Maintenance and Evolution ({ICSME})},
	publisher = {{IEEE}},
	author = {Delplanque, Julien and Etien, Anne and Anquetil, Nicolas and Auverlot, Oliver},
	date = {2018},
}

@incollection{plase_accelerating_2016,
	location = {Riga, Lettland},
	title = {Accelerating Data Queries on Hadoop Framework by using Compact Data Formats},
	booktitle = {{IEEE} 4th Workshop on Advances in Information, Electronic and Electrical Engineering ({AIEEE})},
	publisher = {{IEEE}},
	author = {Plase, Daiga and Niedrite, Laila and Taranovs, Romans},
	date = {2016},
}

@incollection{hu_compared_2018,
	location = {Harbin, China},
	title = {Compared Analysis of Row-Based Storage and Column-Based Storage},
	booktitle = {Eighth International Conference on Instrumentation \& Measurement, Computer, Communication and Control ({IMCCC})},
	publisher = {{IEEE}},
	author = {Hu, Jianping and Wang, Yongyi and Shi, Fan and Xu, Chengxi},
	date = {2018},
}

@incollection{belov_analysis_2021,
	location = {Moskau, Russland},
	title = {Analysis of Big Data Storage Tools for Data Lakes based on Apache Hadoop Platform},
	booktitle = {International Journal of Advanced Computer Science and Applications},
	publisher = {{IEEE}},
	author = {Belov, Vladimir and Nikulchev, Evgeny},
	date = {2021},
}

@book{belov_choosing_2021,
	location = {Moskau, Russland},
	title = {Choosing a Data Storage Format in the Apache Hadoop System Based on Experimental Evaluation Using Apache Spark},
	publisher = {Russian Technological University},
	author = {Belov, Vladimir and Tatarintsev, Andrey and Nikulchev, Evgeny},
	date = {2021},
}

@incollection{ahmed_modern_2017,
	location = {Sahiwal, Pakistan},
	title = {Modern Data Formats for Big Bioinformatics Data Analytics},
	booktitle = {International Journal of Advanced Computer Science and Applications},
	publisher = {{IEEE}},
	author = {Ahmed, Shahzad and Ferzund, Javed and Rehman, Abbas and Ali, M. Usman and Atif Sarwar, Muhammad and Mehmood, Atif},
	date = {2017},
}

@online{confluent_schema_nodate,
	title = {Schema Registry Overview {\textbar} Confluent Documentation},
	url = {https://docs.confluent.io/platform/current/schema-registry/index.html#license},
	author = {Confluent},
	urldate = {2022-12-29},
}

@online{confluent_schema_nodate-1,
	title = {Schema Evolution and Compatibility {\textbar} Confluent Documentation},
	url = {https://docs.confluent.io/platform/current/schema-registry/avro.html#forward-compatibility},
	author = {Confluent},
	urldate = {2022-12-29},
	file = {Schema Evolution and Compatibility | Confluent Documentation:/Users/I538983/Zotero/storage/IZKI46SH/avro.html:text/html},
}

@incollection{armbrust_spark_2015,
	location = {New York, {USA}},
	title = {Spark {SQL}: Relational Data Processing in Spark},
	booktitle = {{SIGMOD} '15: Proceedings of the 2015 {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Armbrust, Michael and Xin, Reynold and Lian, Cheng and Huan, Yin and Liu, Davies and Bradley, Joseph and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael and Ghodsi, Ali and Zaharia, Matei},
	date = {2015},
}

@book{abadi_column-oriented_nodate,
	title = {Column-oriented Database Systems},
	author = {Abadi, Daniel and Boncz, Peter and Harizopoulos, Stavros},
}

@online{sap_was_nodate,
	title = {Was ist Big Data? {\textbar} Fortschrittliche Big-Data-Analysen {\textbar} {SAP} Insights},
	url = {https://www.sap.com/germany/insights/what-is-big-data.html},
	shorttitle = {Was ist Big Data?},
	abstract = {Finden Sie die Big-Data-Lösungen, mit denen Sie einen 360-Grad-Blick auf Ihr Unternehmen gewinnen und bergen Sie bislang verborgene Wachstumschancen. Mehr dazu},
	titleaddon = {{SAP}},
	author = {{SAP}},
	urldate = {2023-01-24},
	file = {Snapshot:/Users/I538983/Zotero/storage/B4W4A8EG/what-is-big-data.html:text/html},
}

@online{verbraucherzentralede_geschichte_nodate,
	title = {Die Geschichte von Big Data},
	url = {https://www.verbraucherzentrale.de/wissen/digitale-welt/datenschutz/die-geschichte-von-big-data-54898},
	abstract = {Datensammeln ist nichts Neues. Aber durch digitale Anwendungen ist es viel einfacher geworden. Wenn alle Daten verknüpft und Individuen zugeordnet werden, kann es für die Privatsphäre eng werden...},
	titleaddon = {Verbraucherzentrale.de},
	author = {Verbraucherzentrale.de},
	urldate = {2023-01-24},
	langid = {german},
	file = {Snapshot:/Users/I538983/Zotero/storage/3UKUG4PA/die-geschichte-von-big-data-54898.html:text/html},
}

@book{nolan_xml_2014,
	location = {New York, {USA}},
	title = {{XML} and Web Technologies for Data Sciences with R},
	publisher = {Springer Science+Business Media},
	author = {Nolan, Deborah and Lang, Duncan Temple},
	date = {2014},
}

@online{snappy_release_nodate,
	title = {Release Snappy 1.1.4 · google/snappy},
	url = {https://github.com/google/snappy/releases/tag/1.1.4},
	abstract = {Fix a 1\% performance regression when snappy is used in {PIE} executables.
Improve compression performance by 5\%.
Improve decompression performance by 20\%.},
	titleaddon = {{GitHub}},
	author = {Snappy},
	urldate = {2023-01-24},
	langid = {english},
	file = {Snapshot:/Users/I538983/Zotero/storage/STQI9EET/snappy.html:text/html},
}

@online{gnucom_gnu_nodate,
	title = {{GNU} Gzip},
	url = {https://www.gnu.org/software/gzip/manual/gzip.html#Overview},
	author = {{GNU}.com},
	urldate = {2023-01-24},
	file = {GNU Gzip:/Users/I538983/Zotero/storage/7CLAQE22/gzip.html:text/html},
}

@online{javadoc_parquetreader_nodate,
	title = {{ParquetReader} (Apache Parquet Hadoop 1.10.1 {API})},
	url = {https://javadoc.io/doc/org.apache.parquet/parquet-hadoop/1.10.1/org/apache/parquet/hadoop/ParquetReader.html},
	author = {{JavaDoc}},
	urldate = {2023-01-24},
	file = {ParquetReader (Apache Parquet Hadoop 1.10.1 API):/Users/I538983/Zotero/storage/B4DAL47X/ParquetReader.html:text/html},
}

@online{orc_using_nodate,
	title = {Using Core Java},
	url = {https://orc.apache.org/docs/core-java.html},
	author = {{ORC}},
	urldate = {2023-01-24},
	file = {Using Core Java:/Users/I538983/Zotero/storage/4EYHDTS3/core-java.html:text/html},
}

@online{apache_datafilereader_nodate,
	title = {{DataFileReader} (Apache Avro Java 1.11.1 {API})},
	url = {https://avro.apache.org/docs/current/api/java/org/apache/avro/file/DataFileReader.html},
	author = {Apache},
	urldate = {2023-01-24},
	file = {DataFileReader (Apache Avro Java 1.11.1 API):/Users/I538983/Zotero/storage/ZN2SLBPH/DataFileReader.html:text/html},
}
